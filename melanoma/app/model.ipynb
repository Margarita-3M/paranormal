{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "elegant-ireland",
   "metadata": {},
   "source": [
    "* [SIIM-ISIC Melanoma Classification](https://www.kaggle.com/c/siim-isic-melanoma-classification)\n",
    "* [\n",
    "Melanoma. Pytorch starter. EfficientNet](https://www.kaggle.com/nroman/melanoma-pytorch-starter-efficientnet)\n",
    "* [Melanoma. Pytorch starter. EfficientNet (copy)](https://www.kaggle.com/valentinaliferov/melanoma-pytorch-starter-efficientnet)\n",
    "* [JPEG Melanoma 256x256](https://www.kaggle.com/cdeotte/jpeg-melanoma-256x256)\n",
    "* [melanoma external malignant 256](https://www.kaggle.com/nroman/melanoma-external-malignant-256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-packet",
   "metadata": {},
   "source": [
    "No sigmoid in forward because we are going to use  \n",
    "**BCEWithLogitsLoss** which applies sigmoid for us when calculating a loss  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "numerical-manual",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -q --upgrade pip gdown onnxruntime efficientnet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-behalf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf sample_data\n",
    "!gdown --id 134YXo0-sJyKO6UqPto8nWFuBmfp3fzx0\n",
    "!unzip -qo melanoma_external_malignant_256.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "working-virus",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from PIL import Image, ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "global-indicator",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "excellent-victoria",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "understood-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "detected-origin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(47)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-hazard",
   "metadata": {},
   "source": [
    "#### NN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "correct-arctic",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_meta_features):\n",
    "        \n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.arch = EfficientNet.from_pretrained('efficientnet-b1')\n",
    "        self.arch._fc = nn.Linear(1280, 500, bias=True)\n",
    "        self.arch.set_swish(memory_efficient=False)\n",
    "        \n",
    "        self.meta = nn.Sequential(\n",
    "            nn.Linear(n_meta_features, 500),\n",
    "            nn.BatchNorm1d(500),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(500, 250),\n",
    "            nn.BatchNorm1d(250),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2))\n",
    "        \n",
    "        self.ouput = nn.Linear(500 + 250, 1)\n",
    "        \n",
    "    def forward(self, x, meta):\n",
    "        cnn_features = self.arch(x)\n",
    "        meta_features = self.meta(meta)\n",
    "        features = torch.cat((cnn_features, meta_features), dim=1)\n",
    "        output = self.ouput(features)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "coordinate-scanning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b1\n"
     ]
    }
   ],
   "source": [
    "model = Net(n_meta_features=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-worship",
   "metadata": {},
   "source": [
    "#### Saving, Loading, and Checking the Model (Torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cloudy-capacity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.48173946142196655"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'model.pt'\n",
    "torch.save(model.state_dict(), path)\n",
    "\n",
    "dev = torch.device('cpu')\n",
    "state = torch.load(path, map_location=dev)\n",
    "model = Net(n_meta_features=12).eval()\n",
    "model.load_state_dict(state)\n",
    "meta = torch.rand(1, 12)\n",
    "x = torch.rand(1, 3, 256, 256)\n",
    "nn.Sigmoid()(model(x, meta)).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-surgeon",
   "metadata": {},
   "source": [
    "#### Saving, Loading, and Checking the Model (ONNX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "acquired-aside",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46756554"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'model.onnx'\n",
    "meta = torch.rand(1,12)\n",
    "x = torch.rand(1,3,256,256)\n",
    "torch.onnx.export(model, (x, meta), path, input_names=['x','meta'])\n",
    "\n",
    "def sigmoid(x): return 1 / (1 + np.exp(-x))\n",
    "onnx_model = onnxruntime.InferenceSession(path)\n",
    "meta = np.random.randn(1, 12).astype(np.float32)\n",
    "x = np.random.randn(1, 3, 256, 256).astype(np.float32)\n",
    "inps = {'x': x, 'meta': meta}\n",
    "outs = onnx_model.run(None, inps)\n",
    "sigmoid(outs[0])[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-collapse",
   "metadata": {},
   "source": [
    "#### Datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unnecessary-injury",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(im):\n",
    "    w, h = im.size; m = np.max([w, h])\n",
    "    hp, hpr = (m - w) // 2, (m - w) % 2\n",
    "    vp, vpr = (m - h) // 2, (m - h) % 2\n",
    "    return (hp + hpr, vp + vpr, hp, vp)\n",
    "\n",
    "def norm(x):\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    return (x - mean) / std\n",
    "\n",
    "def load_image(path, size, transforms):\n",
    "    im = Image.open(path)\n",
    "    im.thumbnail((size,size), Image.ANTIALIAS)\n",
    "    im = ImageOps.expand(im, pad(im))\n",
    "    if transforms: im = transforms(im)\n",
    "    x = np.array(im) / 255.\n",
    "    x = np.float32(norm(x))\n",
    "    return x.transpose(2,0,1)\n",
    "\n",
    "def load_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df.rename(columns={'age_approx':'age'}, inplace=True)\n",
    "    df.rename(columns={'anatom_site_general_challenge':'site'}, inplace=True)\n",
    "    df['site'] = df['site'].str.replace(' ','_')\n",
    "    df['site'] = df['site'].str.replace('/','_')\n",
    "    df.update(df[['sex','site']].fillna('NaN'))\n",
    "    df.update(df['age'].fillna(0))\n",
    "    return df\n",
    "\n",
    "def get_meta_features(sex, age, site):\n",
    "    sites = (\n",
    "        'anterior_torso','head_neck','lateral_torso',\n",
    "        'lower_extremity','oral_genital','palms_soles',\n",
    "        'posterior_torso','torso','upper_extremity','NaN')\n",
    "    max_age = 90\n",
    "    age = age / max_age\n",
    "    sex = {'male':1,'female':0,'unknown':-1}[sex]\n",
    "    m = [sex, age] + [int(s == site) for s in sites]\n",
    "    return np.array(m)\n",
    "\n",
    "class MelanomaDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, path, size, transforms):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.path = path\n",
    "        self.size = size\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        image = f'{self.path}/{row.image_name}.jpg'\n",
    "        x = load_image(image, self.size, self.transforms)\n",
    "        meta = get_meta_features(row.sex, row.age, row.site)\n",
    "        return (x, meta, row.target) if 'target' in self.df.columns else (x, meta)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "champion-buffer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_age = train_df['age'].max()\n",
    "# sites = sorted(train_df['site'].unique().tolist())\n",
    "# sites.remove('NaN'); sites.append('NaN');\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(256, (0.7, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(brightness=32. / 255., saturation=0.5)])\n",
    "\n",
    "# train_dataset = MelanomaDataset(train_df, 'train', 256, train_transforms)\n",
    "# test_dataset = MelanomaDataset(test_df, 'test', 256, None)\n",
    "\n",
    "# train_labels = train_df['target'].to_list()\n",
    "# train_counts = np.unique(train_labels, return_counts=True)[1]\n",
    "# train_weights = torch.Tensor([1. / train_counts[c] for c in train_labels]).double()\n",
    "# train_sampler = torch.utils.data.WeightedRandomSampler(train_weights, len(train_dataset))\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32, num_workers=2, sampler=train_sampler)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=32, num_workers=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "basic-chemical",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = load_data('test.csv')\n",
    "train_df = load_data('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "likely-instrument",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = GroupKFold(n_splits=5)\n",
    "test = MelanomaDataset(test_df, 'test', 256, None)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-wealth",
   "metadata": {},
   "source": [
    "#### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-cincinnati",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1  # Number of epochs to run\n",
    "model_path = 'trained_model.pt'  # Path and filename to save model to\n",
    "es_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\n",
    "TTA = 3 # Test Time Augmentation rounds\n",
    "\n",
    "oof = np.zeros((len(train_df), 1))  # Out Of Fold predictions\n",
    "preds = torch.zeros((len(test), 1), dtype=torch.float32, device=device)  # Predictions for test test\n",
    "\n",
    "# We stratify by target value, thus, according to sklearn StratifiedKFold documentation\n",
    "# We can fill `X` with zeroes of corresponding length to use it as a placeholder\n",
    "# since we only need `y` to stratify the data\n",
    "# for fold, (train_idx, val_idx) in enumerate(skf.split(X=np.zeros(len(train_df)), y=train_df['target']), 1):\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X=np.zeros(len(train_df)), y=train_df['target'], groups=train_df['patient_id'].tolist()), 1):\n",
    "    print('=' * 20, 'Fold', fold, '=' * 20)\n",
    "    \n",
    "    best_val = None  # Best validation score within this fold\n",
    "    patience = es_patience  # Current patience counter\n",
    "    model = Net(n_meta_features=12)  # New model for each fold\n",
    "    model = model.to(device)\n",
    "    \n",
    "    optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = ReduceLROnPlateau(optimizer=optim, mode='max', patience=1, verbose=True, factor=0.2)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    df = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "    train = MelanomaDataset(df, 'train', 256, train_transforms)\n",
    "    \n",
    "    df = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "    val = MelanomaDataset(df, 'train', 256, None)\n",
    "    \n",
    "    train_loader = DataLoader(dataset=train, batch_size=64, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(dataset=val, batch_size=16, shuffle=False, num_workers=2)\n",
    "    test_loader = DataLoader(dataset=test, batch_size=16, shuffle=False, num_workers=2)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        correct = 0\n",
    "        epoch_loss = 0\n",
    "        model.train()\n",
    "        \n",
    "        for x, meta, y in train_loader:\n",
    "            x = torch.tensor(x, device=device, dtype=torch.float32)\n",
    "            meta = torch.tensor(meta, device=device, dtype=torch.float32)\n",
    "            y = torch.tensor(y, device=device, dtype=torch.float32)\n",
    "            optim.zero_grad()\n",
    "            z = model(x, meta)\n",
    "            loss = criterion(z, y.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            pred = torch.round(torch.sigmoid(z))  # round off sigmoid to obtain predictions\n",
    "            correct += (pred.cpu() == y.cpu().unsqueeze(1)).sum().item()  # tracking number of correctly predicted samples\n",
    "            epoch_loss += loss.item()\n",
    "        train_acc = correct / len(train_idx)\n",
    "\n",
    "        model.eval()  # switch model to the evaluation mode\n",
    "        val_preds = torch.zeros((len(val_idx), 1), dtype=torch.float32, device=device)\n",
    "        with torch.no_grad():  # Do not calculate gradient since we are only predicting\n",
    "            # Predicting on validation set\n",
    "            for j, (x_val, meta_val, y_val) in enumerate(val_loader):\n",
    "                x_val = torch.tensor(x_val, device=device, dtype=torch.float32)\n",
    "                meta_val = torch.tensor(meta_val, device=device, dtype=torch.float32)\n",
    "                y_val = torch.tensor(y_val, device=device, dtype=torch.float32)\n",
    "                z_val = model(x_val, meta_val)\n",
    "                val_pred = torch.sigmoid(z_val)\n",
    "                val_preds[j*x_val.shape[0]:j*x_val.shape[0] + x_val.shape[0]] = val_pred\n",
    "            val_acc = accuracy_score(train_df.iloc[val_idx]['target'].values, torch.round(val_preds.cpu()))\n",
    "            val_roc = roc_auc_score(train_df.iloc[val_idx]['target'].values, val_preds.cpu())\n",
    "            \n",
    "            print('Epoch {:03}: | Loss: {:.3f} | Train acc: {:.3f} | Val acc: {:.3f} | Val roc_auc: {:.3f} | Training time: {}'.format(\n",
    "            epoch + 1, \n",
    "            epoch_loss, \n",
    "            train_acc, \n",
    "            val_acc, \n",
    "            val_roc, \n",
    "            str(datetime.timedelta(seconds=time.time() - start_time))[:7]))\n",
    "            \n",
    "            scheduler.step(val_roc)\n",
    "            # During the first iteration (first epoch) best validation is set to None\n",
    "            if not best_val:\n",
    "                best_val = val_roc  # So any validation roc_auc we have is the best one for now\n",
    "                torch.save(model.state_dict(), model_path)  # Saving the model\n",
    "                continue\n",
    "                \n",
    "            if val_roc >= best_val:\n",
    "                best_val = val_roc\n",
    "                patience = es_patience  # Resetting patience since we have new best validation accuracy\n",
    "                torch.save(model.state_dict(), model_path)  # Saving current best model\n",
    "            else:\n",
    "                patience -= 1\n",
    "                if patience == 0:\n",
    "                    print('Early stopping. Best Val roc_auc: {:.3f}'.format(best_val))\n",
    "                    break\n",
    "                \n",
    "    # model = torch.load(model_path)  # Loading best model of this fold\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()  # switch model to the evaluation mode\n",
    "    val_preds = torch.zeros((len(val_idx), 1), dtype=torch.float32, device=device)\n",
    "    with torch.no_grad():\n",
    "        # Predicting on validation set once again to obtain data for OOF\n",
    "        for j, (x_val, meta_val, y_val) in enumerate(val_loader):\n",
    "            x_val = torch.tensor(x_val, device=device, dtype=torch.float32)\n",
    "            meta_val = torch.tensor(meta_val, device=device, dtype=torch.float32)\n",
    "            y_val = torch.tensor(y_val, device=device, dtype=torch.float32)\n",
    "            z_val = model(x_val, meta_val)\n",
    "            val_pred = torch.sigmoid(z_val)\n",
    "            val_preds[j*x_val.shape[0]:j*x_val.shape[0] + x_val.shape[0]] = val_pred\n",
    "        oof[val_idx] = val_preds.cpu().numpy()\n",
    "        \n",
    "        # Predicting on test set\n",
    "        for _ in range(TTA):\n",
    "            for i, (x_test, meta_test) in enumerate(test_loader):\n",
    "                x_test = torch.tensor(x_test, device=device, dtype=torch.float32)\n",
    "                meta_test = torch.tensor(meta_test, device=device, dtype=torch.float32)\n",
    "                z_test = model(x_test, meta_test)\n",
    "                z_test = torch.sigmoid(z_test)\n",
    "                preds[i*x_test.shape[0]:i*x_test.shape[0] + x_test.shape[0]] += z_test\n",
    "        preds /= TTA\n",
    "        \n",
    "    del train, val, train_loader, val_loader, x, y, x_val, y_val\n",
    "    gc.collect()\n",
    "    \n",
    "preds /= skf.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-valley",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('OOF: {:.3f}'.format(roc_auc_score(train_df['target'], oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-compatibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(pd.Series(preds.cpu().numpy().reshape(-1,)));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-species",
   "metadata": {},
   "source": [
    "#### Making a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-signal",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submission.csv')\n",
    "sub['target'] = preds.cpu().numpy().reshape(-1,)\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
